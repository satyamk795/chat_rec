{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOaRPs54yvyK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datasets import Dataset\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"chats.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "rZkGLhRez5Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()\n",
        "df['Message']=df['Message'].astype(str)"
      ],
      "metadata": {
        "id": "hJN_FbOf0BNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['context']=\"\"\n",
        "for i in range(1,len(df)):\n",
        "    df.loc[i,'context']=\" \".join(df.loc[:i-1,'Message'].tail(3).values)"
      ],
      "metadata": {
        "id": "f47-WtNM0Rl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts,test_texts=train_test_split(df,test_size=0.1,random_state=42)\n",
        "train_df=pd.DataFrame(train_texts)\n",
        "test_df=pd.DataFrame(test_texts)"
      ],
      "metadata": {
        "id": "2x4XAu6C0aZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "id": "TnmvmXA70eKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    tokenized_inputs = tokenizer([c + \" \" + m for c, m in zip(batch['context'], batch['Message'])],\n",
        "                                 padding='max_length', truncation=True, max_length=128)\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "0QU5BTTE0i9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=Dataset.from_pandas(train_df).map(tokenize,batched=True)\n",
        "test_dataset=Dataset.from_pandas(test_df).map(tokenize,batched=True)\n",
        "train_dataset.set_format(type='torch',columns=['input_ids','attention_mask'])\n",
        "test_dataset.set_format(type='torch',columns=['input_ids','attention_mask'])"
      ],
      "metadata": {
        "id": "977Mtgo901Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "72k1NIfT1RGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args=TrainingArguments(output_dir=\"./results\",num_train_epochs=1,per_device_train_batch_size=2,per_device_eval_batch_size=2,warmup_steps=10,logging_dir=\"./logs\",save_strategy=\"no\")\n",
        "trainer=Trainer(model=model,args=training_args,train_dataset=train_dataset,eval_dataset=test_dataset)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "l7xqhsRE1sbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reply(context):\n",
        "    inputs=tokenizer.encode(context,return_tensors='pt')\n",
        "    outputs=model.generate(inputs,max_length=50,num_return_sequences=1,pad_token_id=tokenizer.eos_token_id)\n",
        "    return tokenizer.decode(outputs[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "WzqxGKwJ1xxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample=df.sample(3)\n",
        "for _,row in sample.iterrows():\n",
        "    c=row['context']\n",
        "    print(\"Context:\",c)\n",
        "    print(\"Generated:\",generate_reply(c))\n",
        "    print()"
      ],
      "metadata": {
        "id": "y9BtPpdV13g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refs=[row['Message'].split() for _,row in test_df.head(10).iterrows()]\n",
        "hyps=[generate_reply(row['context']).split() for _,row in test_df.head(10).iterrows()]\n",
        "bleu_scores=[sentence_bleu([r],h) for r,h in zip(refs,hyps)]\n",
        "print(\"Average BLEU:\",np.mean(bleu_scores))"
      ],
      "metadata": {
        "id": "vnWyJEdE2Et-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model,\"Model.joblib\")\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "id": "kIXomrBb2K3u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}